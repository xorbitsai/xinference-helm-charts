###############################################################################################
#
# This example demonstrates how to set up a truly distributed Xinference cluster in Kubernetes.
# In this scenario, there are 4 workers, each requiring 8 GPUs.
# To achieve this effect, the main changes were made to
# the `config.worker_num` and `xinferenceWorker.worker.resources` parameters.
#
###############################################################################################

# common used configurations
config:
  xinference_image: ""
  curl_image: curlimages/curl:8.8.0
  image_pull_policy: ""
  worker_num: 4
  model_src: "huggingface"
  persistence:
    enabled: false
    mountPath: "/data"
  # any other environments
  extra_envs: {}
storageClass:
  name: local-storage
  spec:
    # place your configs here for the storage class
    provisioner: kubernetes.io/no-provisioner
    volumeBindingMode: WaitForFirstConsumer
pv:
  accessModes:
    - ReadWriteMany
  capacity:
    # actually no limit for local-storage.
    # if you want to change this, your storage class should support `resize`
    storage: 20Gi
  hostPath:
    path: /tmp/xinference
  persistentVolumeReclaimPolicy: Delete
  storageClassName: "local-storage"
pvc:
  accessModes:
    # the volume can be mounted as read-write by many nodes.
    - ReadWriteMany
  sharedVolumeClaim:
    storageRequest: 10Gi
  storageClassName: "local-storage"
  volumeMode: ""
serviceWeb:
  ports:
  - nodePort: 30003
    port: 9997
    protocol: TCP
    targetPort: 9997
  # change this to `LoadBalancer` if you use cloud platform
  type: NodePort
serviceSupervisor:
  ports:
  - name: service-supervisor-oscar
    port: 9999
    protocol: TCP
    targetPort: 9999
  - name: service-supervisor-web
    port: 9997
    protocol: TCP
    targetPort: 9997
  type: ClusterIP
serviceWorker:
  ports:
  - port: 30001
    protocol: TCP
    targetPort: 30001
  type: ClusterIP
xinferenceSupervisor:
  supervisor:
    args:
    - --port
    - "9997"
    - --host
    - $(POD_IP)
    - --supervisor-port
    - "9999"
    - --log-level
    - debug
    ports:
      - containerPort: 9997
        name: web
      - containerPort: 9999
        name: oscar
    resources:
      requests:
        cpu: "1"
        memory: 4Gi
xinferenceWorker:
  strategy:
    type: Recreate
  worker:
    initContainers:
      command: [ 'sh', '-c', "until curl -v http://service-supervisor:9997/v1/address; do echo waiting for supervisor; sleep 1; done" ]
    args:
    - -e
    - http://service-supervisor:9997
    - --host
    - $(POD_IP)
    - --worker-port
    - "30001"
    - --log-level
    - debug
    ports:
      - containerPort: 30001
    resources:
      requests:
        cpu: "2"
        memory: 8Gi
        nvidia.com/gpu: "8"
      limits:
        cpu: "2"
        memory: 8Gi
        nvidia.com/gpu: "8"
